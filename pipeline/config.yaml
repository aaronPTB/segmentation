---
num_workers: 4
experiment_name: "2021-12-30"

val_split: 0.1

model:
  type: segmentation_models_pytorch.Unet
  encoder_name: timm-efficientnet-b3
  classes: 1  # Only do binary fashion segmentation
  encoder_weights: noisy-student

trainer:
  type: pytorch_lightning.Trainer
  gpus: 1
  max_epochs: 30
  distributed_backend: ddp
  progress_bar_refresh_rate: 1
  benchmark: True
  precision: 16 # Use 16 bit precision instead of 32
  gradient_clip_val: 5.0
  num_sanity_val_steps: 2
  sync_batchnorm: True
#  resume_from_checkpoint: 2020-10-30/epoch=67.ckpt


scheduler:
  type: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  T_0: 10
  T_mult: 2

train_parameters:
  batch_size: 8

checkpoint_callback:
  type: pytorch_lightning.callbacks.ModelCheckpoint
  filepath: "checkpoints"
  monitor: val_iou
  verbose: True
  mode: max
  save_top_k: -1

val_parameters:
  batch_size: 8

optimizer:
  type: adamp.AdamP
  lr: 0.0001


train_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
     # Resize all images to smaller size and apply transformations
      - __class_fulname__: albumentations.augmentations.geometric.resize.Resize
        always_apply: True
        height: 400
        width: 400
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.LongestMaxSize
        always_apply: False
        max_size: 400
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.PadIfNeeded
        always_apply: False
        min_height: 400
        min_width: 400
        border_mode: 0 # cv2.BORDER_CONSTANT
        value: 0
        mask_value: 0
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.RandomCrop
        always_apply: False
        height: 312
        width: 312
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.HorizontalFlip
        always_apply: False
        p: 0.5
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225

val_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fulname__: albumentations.augmentations.geometric.resize.Resize
        always_apply: True
        height: 400
        width: 400
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.LongestMaxSize
        always_apply: False
        max_size: 400
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.PadIfNeeded
        always_apply: False
        min_height: 400
        min_width: 400
        border_mode: 0 # cv2.BORDER_CONSTANT
        value: 0
        mask_value: 0
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225

test_aug:
  transform:
    __class_fullname__: albumentations.core.composition.Compose
    bbox_params: null
    keypoint_params: null
    p: 1
    transforms:
      - __class_fulname__: albumentations.augmentations.geometric.resize.Resize
        always_apply: True
        height: 400
        width: 400
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.LongestMaxSize
        always_apply: False
        max_size: 400
        p: 1
      - __class_fullname__: albumentations.augmentations.transforms.Normalize
        always_apply: false
        max_pixel_value: 255.0
        mean:
          - 0.485
          - 0.456
          - 0.406
        p: 1
        std:
          - 0.229
          - 0.224
          - 0.225
